{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d02ca29-efa2-4dfe-b1f3-2e0f30336cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to copy chest_xray_dataset/train/PNEUMONIA/.ipynb_checkpoints to dataset/PNEUMONIA/.ipynb_checkpoints: [Errno 21] Is a directory: 'chest_xray_dataset/train/PNEUMONIA/.ipynb_checkpoints'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "data_path = 'chest_xray_dataset'\n",
    "combined_path = 'dataset'\n",
    "os.makedirs(combined_path, exist_ok=True)\n",
    "\n",
    "# Combine all images from train, val, and test into a single directory for each class\n",
    "for split in ['train', 'val', 'test']:\n",
    "    for class_name in ['NORMAL', 'PNEUMONIA']:\n",
    "        source_dir = os.path.join(data_path, split, class_name)\n",
    "        target_dir = os.path.join(combined_path, class_name)\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "        \n",
    "        # Check if source directory exists\n",
    "        if not os.path.exists(source_dir):\n",
    "            print(f\"Source directory {source_dir} does not exist. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        for file_name in os.listdir(source_dir):\n",
    "            source_file = os.path.join(source_dir, file_name)\n",
    "            target_file = os.path.join(target_dir, file_name)\n",
    "            \n",
    "            # Check if the file already exists in the target directory to avoid overwriting\n",
    "            if os.path.exists(target_file):\n",
    "                print(f\"File {target_file} already exists. Skipping.\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                shutil.copyfile(source_file, target_file)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to copy {source_file} to {target_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2799b12-5e54-4a66-a192-830c8d413457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),  # Convert images to grayscale if not already\n",
    "    transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.CenterCrop(size=224),\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize the images\n",
    "])\n",
    "\n",
    "\n",
    "# Load the combined dataset\n",
    "combined_dataset = datasets.ImageFolder(combined_path, transform=transform)\n",
    "\n",
    "# Separate NORMAL and PNEUMONIA datasets\n",
    "normal_indices = [i for i, (img, label) in enumerate(combined_dataset) if label == combined_dataset.class_to_idx['NORMAL']]\n",
    "pneumonia_indices = [i for i, (img, label) in enumerate(combined_dataset) if label == combined_dataset.class_to_idx['PNEUMONIA']]\n",
    "\n",
    "normal_dataset = Subset(combined_dataset, normal_indices)\n",
    "pneumonia_dataset = Subset(combined_dataset, pneumonia_indices)\n",
    "\n",
    "# Create data loaders for each class\n",
    "batch_size = 32\n",
    "normal_loader = DataLoader(normal_dataset, batch_size=batch_size, shuffle=True)\n",
    "pneumonia_loader = DataLoader(pneumonia_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c419a123-2429-4e2f-9980-a90e1e173098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 1, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Flatten(),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a66cc4cc-fd66-4732-8bf0-b7c3e0990905",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "netG = Generator().to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "fixed_noise = torch.randn(64, 100, 1, 1, device=device)\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "optimizerD = torch.optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizerG = torch.optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "118d5cad-b9e3-4438-af05-1f30a509d17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] Step [0/50] Loss_D: 1.4386096000671387 Loss_G: 4.743978500366211 D(x): 0.5296969413757324 D(G(z)): 0.54376220703125/0.009061941877007484\n",
      "Epoch [2/20] Step [0/50] Loss_D: 0.008851748891174793 Loss_G: 7.3370041847229 D(x): 0.9937028288841248 D(G(z)): 0.002529300982132554/0.0006698048673570156\n",
      "Epoch [3/20] Step [0/50] Loss_D: 0.0037087153177708387 Loss_G: 7.968418121337891 D(x): 0.9974547624588013 D(G(z)): 0.0011592459632083774/0.00036303841625340283\n",
      "Epoch [4/20] Step [0/50] Loss_D: 0.0024849469773471355 Loss_G: 8.21082878112793 D(x): 0.9982721209526062 D(G(z)): 0.0007549664005637169/0.0002921766717918217\n",
      "Epoch [5/20] Step [0/50] Loss_D: 0.0019377145217731595 Loss_G: 8.05799674987793 D(x): 0.9987524151802063 D(G(z)): 0.0006889909273013473/0.00035352923441678286\n",
      "Epoch [6/20] Step [0/50] Loss_D: 0.0012646547984331846 Loss_G: 8.537962913513184 D(x): 0.9990653991699219 D(G(z)): 0.0003294643247500062/0.00021172550623305142\n",
      "Epoch [7/20] Step [0/50] Loss_D: 0.0008603736641816795 Loss_G: 8.733034133911133 D(x): 0.9995037317276001 D(G(z)): 0.00036388076841831207/0.00016808258078526706\n",
      "Epoch [8/20] Step [0/50] Loss_D: 0.0006626781541854143 Loss_G: 8.768513679504395 D(x): 0.9995964169502258 D(G(z)): 0.0002589728101156652/0.000156355497892946\n",
      "Epoch [9/20] Step [0/50] Loss_D: 0.0005366582772694528 Loss_G: 8.97507095336914 D(x): 0.9996676445007324 D(G(z)): 0.00020420784130692482/0.0001269491040147841\n",
      "Epoch [10/20] Step [0/50] Loss_D: 0.0003941771574318409 Loss_G: 9.29079818725586 D(x): 0.999731183052063 D(G(z)): 0.00012534258712548763/9.258746285922825e-05\n",
      "Epoch [11/20] Step [0/50] Loss_D: 0.0004571314202621579 Loss_G: 9.134839057922363 D(x): 0.999718189239502 D(G(z)): 0.0001752427197061479/0.00010838355228770524\n",
      "Epoch [12/20] Step [0/50] Loss_D: 0.0003932253166567534 Loss_G: 9.512943267822266 D(x): 0.9997010231018066 D(G(z)): 9.421449794899672e-05/7.42640913813375e-05\n",
      "Epoch [13/20] Step [0/50] Loss_D: 0.0013502966612577438 Loss_G: 9.307048797607422 D(x): 0.9987316131591797 D(G(z)): 8.027339936234057e-05/9.169413533527404e-05\n",
      "Epoch [14/20] Step [0/50] Loss_D: 0.0004056044272147119 Loss_G: 9.722830772399902 D(x): 0.9996688961982727 D(G(z)): 7.44321005186066e-05/6.114620191510767e-05\n",
      "Epoch [15/20] Step [0/50] Loss_D: 0.000363727769581601 Loss_G: 9.500513076782227 D(x): 0.9997575879096985 D(G(z)): 0.00012128901289543137/7.634537905687466e-05\n",
      "Epoch [16/20] Step [0/50] Loss_D: 0.0002418496587779373 Loss_G: 9.962362289428711 D(x): 0.9998170137405396 D(G(z)): 5.8821467973757535e-05/4.778285074280575e-05\n",
      "Epoch [17/20] Step [0/50] Loss_D: 0.0001755979610607028 Loss_G: 10.035526275634766 D(x): 0.9998879432678223 D(G(z)): 6.353406934067607e-05/4.454564259503968e-05\n",
      "Epoch [18/20] Step [0/50] Loss_D: 0.00017690287495497614 Loss_G: 9.615175247192383 D(x): 0.9999144077301025 D(G(z)): 9.126125951297581e-05/6.725137791363522e-05\n",
      "Epoch [19/20] Step [0/50] Loss_D: 0.00012684905959758908 Loss_G: 9.938209533691406 D(x): 0.9999368190765381 D(G(z)): 6.369415496010333e-05/4.875651211477816e-05\n",
      "Epoch [20/20] Step [0/50] Loss_D: 0.00010825516801560298 Loss_G: 10.276163101196289 D(x): 0.9999326467514038 D(G(z)): 4.094950418220833e-05/3.543645652825944e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "save_dir = 'NORMAL'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(normal_loader, 0):\n",
    "        # Concatenate list of tensors into a single tensor\n",
    "        real_images, _ = data\n",
    "        real_images = real_images.to(device)\n",
    "        # Train Discriminator with real batch\n",
    "        netD.zero_grad()\n",
    "        batch_size = real_images.size(0)\n",
    "        labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "        output = netD(real_images).mean(1)\n",
    "\n",
    "        errD_real = criterion(output, labels)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # Train Discriminator with fake batch\n",
    "        noise = torch.randn(batch_size, 100, 1, 1, device=device)\n",
    "        fake_images = netG(noise)\n",
    "        labels.fill_(fake_label)\n",
    "        output = netD(fake_images.detach()).mean(1)\n",
    "        errD_fake = criterion(output, labels)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Train Generator\n",
    "        netG.zero_grad()\n",
    "        labels.fill_(real_label)\n",
    "        output = netD(fake_images).mean(1)\n",
    "        errG = criterion(output, labels)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Print training stats\n",
    "        if i % 50 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}] Step [{i}/{len(normal_loader)}] Loss_D: {errD.item()} Loss_G: {errG.item()} D(x): {D_x} D(G(z)): {D_G_z1}/{D_G_z2}')\n",
    "\n",
    "    # Save generated images for every epoch\n",
    "    with torch.no_grad():\n",
    "        fake_images = netG(fixed_noise).detach().cpu()\n",
    "        grid = vutils.make_grid(fake_images, padding=2, normalize=True)\n",
    "        plt.imshow(grid.permute(1, 2, 0), cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "        # Save images to folder\n",
    "        for idx, image in enumerate(fake_images):\n",
    "            save_path = os.path.join(save_dir, f'epoch_{epoch+1}_image_{idx+1}.png')\n",
    "            save_image(image, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f90e8a-908b-47f7-afd1-cfc3d71cb9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] Step [0/134] Loss_D: 9.413693624082953e-05 Loss_G: 10.29275131225586 D(x): 0.9999514818191528 D(G(z)): 4.556115163723007e-05/3.6096604162594303e-05\n",
      "Epoch [1/20] Step [50/134] Loss_D: 6.797494279453531e-05 Loss_G: 10.678693771362305 D(x): 0.99996018409729 D(G(z)): 2.8111247956985608e-05/2.4465041860821657e-05\n",
      "Epoch [1/20] Step [100/134] Loss_D: 6.807357567595318e-05 Loss_G: 10.558014869689941 D(x): 0.9999641180038452 D(G(z)): 3.215175092918798e-05/2.731109270825982e-05\n",
      "Epoch [2/20] Step [0/134] Loss_D: 6.109396053943783e-05 Loss_G: 10.523611068725586 D(x): 0.9999715089797974 D(G(z)): 3.2563657441642135e-05/2.8285816370043904e-05\n",
      "Epoch [2/20] Step [50/134] Loss_D: 7.023988291621208e-05 Loss_G: 10.369918823242188 D(x): 0.9999679327011108 D(G(z)): 3.813865623669699e-05/3.219324571546167e-05\n",
      "Epoch [2/20] Step [100/134] Loss_D: 5.532328214030713e-05 Loss_G: 10.721857070922852 D(x): 0.9999710917472839 D(G(z)): 2.640854836499784e-05/2.2777199774282053e-05\n",
      "Epoch [3/20] Step [0/134] Loss_D: 7.399410242214799e-05 Loss_G: 10.840768814086914 D(x): 0.999950110912323 D(G(z)): 2.4108800062094815e-05/2.0572959329001606e-05\n",
      "Epoch [3/20] Step [50/134] Loss_D: 3.928363003069535e-05 Loss_G: 11.242696762084961 D(x): 0.9999755620956421 D(G(z)): 1.4836424270470161e-05/1.3598297300632112e-05\n",
      "Epoch [3/20] Step [100/134] Loss_D: 4.5994944230187684e-05 Loss_G: 11.079629898071289 D(x): 0.9999721050262451 D(G(z)): 1.8086266209138557e-05/1.6355763364117593e-05\n",
      "Epoch [4/20] Step [0/134] Loss_D: 5.01395006722305e-05 Loss_G: 11.129270553588867 D(x): 0.9999666810035706 D(G(z)): 1.6778549252194352e-05/1.5300172890420072e-05\n",
      "Epoch [4/20] Step [50/134] Loss_D: 4.230309423292056e-05 Loss_G: 11.250326156616211 D(x): 0.9999721050262451 D(G(z)): 1.4443644431594294e-05/1.3374039554037154e-05\n",
      "Epoch [4/20] Step [100/134] Loss_D: 3.537761222105473e-05 Loss_G: 11.315441131591797 D(x): 0.9999787211418152 D(G(z)): 1.4129188457445707e-05/1.2924811017001048e-05\n",
      "Epoch [5/20] Step [0/134] Loss_D: 3.0191913538146764e-05 Loss_G: 11.431846618652344 D(x): 0.9999827146530151 D(G(z)): 1.2938520740135573e-05/1.186080407933332e-05\n",
      "Epoch [5/20] Step [50/134] Loss_D: 3.9954204112291336e-05 Loss_G: 10.92811393737793 D(x): 0.9999829530715942 D(G(z)): 2.294872138008941e-05/1.9653938579722308e-05\n",
      "Epoch [5/20] Step [100/134] Loss_D: 2.847448195097968e-05 Loss_G: 11.329048156738281 D(x): 0.9999852776527405 D(G(z)): 1.3737062545260414e-05/1.2478679309424479e-05\n",
      "Epoch [6/20] Step [0/134] Loss_D: 2.6334273570682853e-05 Loss_G: 11.490464210510254 D(x): 0.999985933303833 D(G(z)): 1.224171955982456e-05/1.1243852895859163e-05\n",
      "Epoch [6/20] Step [50/134] Loss_D: 3.311441105324775e-05 Loss_G: 11.260128021240234 D(x): 0.999981701374054 D(G(z)): 1.4817824194324203e-05/1.3409906387096271e-05\n",
      "Epoch [6/20] Step [100/134] Loss_D: 2.927919376816135e-05 Loss_G: 11.392719268798828 D(x): 0.9999834895133972 D(G(z)): 1.279473872273229e-05/1.1663285476970486e-05\n",
      "Epoch [7/20] Step [0/134] Loss_D: 5.094645530334674e-05 Loss_G: 11.416966438293457 D(x): 0.9999618530273438 D(G(z)): 1.2797214367310517e-05/1.1784601156250574e-05\n",
      "Epoch [7/20] Step [50/134] Loss_D: 7.036153692752123e-05 Loss_G: 11.181343078613281 D(x): 0.9999568462371826 D(G(z)): 2.7240539566264488e-05/1.3997835594636854e-05\n",
      "Epoch [7/20] Step [100/134] Loss_D: 7.872819696785882e-05 Loss_G: 11.34572696685791 D(x): 0.9999356269836426 D(G(z)): 1.4380482753040269e-05/1.2036629414069466e-05\n",
      "Epoch [8/20] Step [0/134] Loss_D: 3.612643922679126e-05 Loss_G: 11.483681678771973 D(x): 0.9999754428863525 D(G(z)): 1.1579368219827302e-05/1.0414947610115632e-05\n",
      "Epoch [8/20] Step [50/134] Loss_D: 3.701129026012495e-05 Loss_G: 11.782824516296387 D(x): 0.9999709725379944 D(G(z)): 7.948462553031277e-06/7.668401849514339e-06\n",
      "Epoch [8/20] Step [100/134] Loss_D: 4.013508805655874e-05 Loss_G: 11.645240783691406 D(x): 0.9999691247940063 D(G(z)): 9.290396519645583e-06/8.814070497464854e-06\n",
      "Epoch [9/20] Step [0/134] Loss_D: 2.6427489501656964e-05 Loss_G: 11.953472137451172 D(x): 0.9999806880950928 D(G(z)): 7.096871740941424e-06/6.484176992671564e-06\n",
      "Epoch [9/20] Step [50/134] Loss_D: 2.6071669708471745e-05 Loss_G: 11.743599891662598 D(x): 0.9999829530715942 D(G(z)): 9.012509508465882e-06/8.027796866372228e-06\n",
      "Epoch [9/20] Step [100/134] Loss_D: 2.3498034352087416e-05 Loss_G: 12.306217193603516 D(x): 0.9999813437461853 D(G(z)): 4.806375727639534e-06/4.658357738662744e-06\n",
      "Epoch [10/20] Step [0/134] Loss_D: 2.117657641065307e-05 Loss_G: 12.160673141479492 D(x): 0.9999847412109375 D(G(z)): 5.8962955336028244e-06/5.447452167572919e-06\n",
      "Epoch [10/20] Step [50/134] Loss_D: 2.365390901104547e-05 Loss_G: 11.699714660644531 D(x): 0.9999868869781494 D(G(z)): 1.050447372108465e-05/9.199025043926667e-06\n",
      "Epoch [10/20] Step [100/134] Loss_D: 1.6288920960505493e-05 Loss_G: 12.236324310302734 D(x): 0.99998939037323 D(G(z)): 5.6729386415099725e-06/5.279033757688012e-06\n",
      "Epoch [11/20] Step [0/134] Loss_D: 1.637460445635952e-05 Loss_G: 12.400229454040527 D(x): 0.9999884366989136 D(G(z)): 4.778153652296169e-06/4.51980713478406e-06\n",
      "Epoch [11/20] Step [50/134] Loss_D: 1.2178023098385893e-05 Loss_G: 12.416816711425781 D(x): 0.9999923706054688 D(G(z)): 4.519373760558665e-06/4.316671493143076e-06\n",
      "Epoch [11/20] Step [100/134] Loss_D: 1.5482382877962664e-05 Loss_G: 11.9904203414917 D(x): 0.9999915957450867 D(G(z)): 7.07729896021192e-06/6.6199681896250695e-06\n",
      "Epoch [12/20] Step [0/134] Loss_D: 1.4264196579460986e-05 Loss_G: 11.858001708984375 D(x): 0.9999938607215881 D(G(z)): 8.126734428515192e-06/7.572932190669235e-06\n",
      "Epoch [12/20] Step [50/134] Loss_D: 1.3468839824781753e-05 Loss_G: 11.782418251037598 D(x): 0.999995231628418 D(G(z)): 8.688674824952614e-06/7.884084880060982e-06\n",
      "Epoch [12/20] Step [100/134] Loss_D: 1.3122384189045988e-05 Loss_G: 12.115878105163574 D(x): 0.9999932050704956 D(G(z)): 6.343635504890699e-06/5.75812464376213e-06\n",
      "Epoch [13/20] Step [0/134] Loss_D: 1.5268173228832893e-05 Loss_G: 12.070897102355957 D(x): 0.999991774559021 D(G(z)): 7.043478035484441e-06/6.20305127085885e-06\n",
      "Epoch [13/20] Step [50/134] Loss_D: 1.179617720481474e-05 Loss_G: 12.40928840637207 D(x): 0.9999929070472717 D(G(z)): 4.708511369244661e-06/4.355598775873659e-06\n",
      "Epoch [13/20] Step [100/134] Loss_D: 1.6335492546204478e-05 Loss_G: 12.427855491638184 D(x): 0.999988317489624 D(G(z)): 4.619278115569614e-06/4.3571753849391825e-06\n",
      "Epoch [14/20] Step [0/134] Loss_D: 1.1283955245744437e-05 Loss_G: 12.936189651489258 D(x): 0.9999914169311523 D(G(z)): 2.675684299902059e-06/2.56102111961809e-06\n",
      "Epoch [14/20] Step [50/134] Loss_D: 9.654118002799805e-06 Loss_G: 12.765013694763184 D(x): 0.9999935030937195 D(G(z)): 3.1384281555801863e-06/2.9876352982682874e-06\n",
      "Epoch [14/20] Step [100/134] Loss_D: 8.23104983282974e-06 Loss_G: 12.700935363769531 D(x): 0.999995231628418 D(G(z)): 3.4241109005961334e-06/3.2539937819819897e-06\n",
      "Epoch [15/20] Step [0/134] Loss_D: 7.532555628131377e-06 Loss_G: 13.039419174194336 D(x): 0.9999948740005493 D(G(z)): 2.4380915419897065e-06/2.3401180442306213e-06\n",
      "Epoch [15/20] Step [50/134] Loss_D: 6.405650310625788e-06 Loss_G: 13.33719253540039 D(x): 0.9999954104423523 D(G(z)): 1.8439399127601064e-06/1.7908923837239854e-06\n",
      "Epoch [15/20] Step [100/134] Loss_D: 6.7949445110571105e-06 Loss_G: 13.216278076171875 D(x): 0.999995231628418 D(G(z)): 2.0784602838830324e-06/2.0147895156696904e-06\n",
      "Epoch [16/20] Step [0/134] Loss_D: 6.033120371284895e-06 Loss_G: 13.379060745239258 D(x): 0.9999957084655762 D(G(z)): 1.7070733520085923e-06/1.6672306628606748e-06\n",
      "Epoch [16/20] Step [50/134] Loss_D: 5.900872110942146e-06 Loss_G: 13.420915603637695 D(x): 0.9999957084655762 D(G(z)): 1.6272462062261184e-06/1.5884043023106642e-06\n",
      "Epoch [16/20] Step [100/134] Loss_D: 6.4354549067502376e-06 Loss_G: 13.216480255126953 D(x): 0.9999955892562866 D(G(z)): 2.0031825442856643e-06/1.9480494302115403e-06\n",
      "Epoch [17/20] Step [0/134] Loss_D: 5.731368673878023e-06 Loss_G: 13.103116989135742 D(x): 0.999996542930603 D(G(z)): 2.3015206807031063e-06/2.2155363694764674e-06\n",
      "Epoch [17/20] Step [50/134] Loss_D: 7.2494322012062185e-06 Loss_G: 12.967813491821289 D(x): 0.9999952912330627 D(G(z)): 2.5247377379855607e-06/2.4388973542954773e-06\n",
      "Epoch [17/20] Step [100/134] Loss_D: 6.3069287534744944e-06 Loss_G: 13.098981857299805 D(x): 0.9999959468841553 D(G(z)): 2.2552576410816982e-06/2.1862856556253973e-06\n",
      "Epoch [18/20] Step [0/134] Loss_D: 5.781659638159908e-06 Loss_G: 12.890308380126953 D(x): 0.9999970197677612 D(G(z)): 2.8097438189433888e-06/2.6986699594999664e-06\n",
      "Epoch [18/20] Step [50/134] Loss_D: 4.8391593736596406e-06 Loss_G: 13.210652351379395 D(x): 0.9999971389770508 D(G(z)): 1.976152361748973e-06/1.9191420506103896e-06\n",
      "Epoch [18/20] Step [100/134] Loss_D: 6.066646619728999e-06 Loss_G: 13.181059837341309 D(x): 0.9999959468841553 D(G(z)): 2.0513575691438746e-06/1.9842814253934193e-06\n",
      "Epoch [19/20] Step [0/134] Loss_D: 1.0679017577785999e-05 Loss_G: 13.191286087036133 D(x): 0.9999912977218628 D(G(z)): 2.0252623471606057e-06/1.9643691757664783e-06\n",
      "Epoch [19/20] Step [50/134] Loss_D: 5.289919954520883e-06 Loss_G: 12.939037322998047 D(x): 0.9999973177909851 D(G(z)): 2.604697783681331e-06/2.485969616827788e-06\n",
      "Epoch [19/20] Step [100/134] Loss_D: 6.889938049425837e-06 Loss_G: 12.585050582885742 D(x): 0.9999969601631165 D(G(z)): 3.8327634683810174e-06/3.5529919841792434e-06\n",
      "Epoch [20/20] Step [0/134] Loss_D: 5.18747447131318e-06 Loss_G: 12.964725494384766 D(x): 0.9999973773956299 D(G(z)): 2.539304205129156e-06/2.4021683202590793e-06\n",
      "Epoch [20/20] Step [50/134] Loss_D: 6.0666457102342974e-06 Loss_G: 12.814441680908203 D(x): 0.9999969005584717 D(G(z)): 2.9820682811987353e-06/2.7982700885331724e-06\n",
      "Epoch [20/20] Step [100/134] Loss_D: 4.913666089123581e-06 Loss_G: 13.277397155761719 D(x): 0.9999969005584717 D(G(z)): 1.8267072618982638e-06/1.7481697796029039e-06\n"
     ]
    }
   ],
   "source": [
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "save_dir = 'PNEUMONIA'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(pneumonia_loader, 0):\n",
    "        # Concatenate list of tensors into a single tensor\n",
    "        real_images, _ = data\n",
    "        real_images = real_images.to(device)\n",
    "        # Train Discriminator with real batch\n",
    "        netD.zero_grad()\n",
    "        batch_size = real_images.size(0)\n",
    "        labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "        output = netD(real_images).mean(1)\n",
    "\n",
    "        errD_real = criterion(output, labels)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # Train Discriminator with fake batch\n",
    "        noise = torch.randn(batch_size, 100, 1, 1, device=device)\n",
    "        fake_images = netG(noise)\n",
    "        labels.fill_(fake_label)\n",
    "        output = netD(fake_images.detach()).mean(1)\n",
    "        errD_fake = criterion(output, labels)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Train Generator\n",
    "        netG.zero_grad()\n",
    "        labels.fill_(real_label)\n",
    "        output = netD(fake_images).mean(1)\n",
    "        errG = criterion(output, labels)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Print training stats\n",
    "        if i % 50 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}] Step [{i}/{len(pneumonia_loader)}] Loss_D: {errD.item()} Loss_G: {errG.item()} D(x): {D_x} D(G(z)): {D_G_z1}/{D_G_z2}')\n",
    "\n",
    "    # Save generated images for every epoch\n",
    "    with torch.no_grad():\n",
    "        fake_images = netG(fixed_noise).detach().cpu()\n",
    "        grid = vutils.make_grid(fake_images, padding=2, normalize=True)\n",
    "        plt.imshow(grid.permute(1, 2, 0), cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "        # Save images to folder\n",
    "        for idx, image in enumerate(fake_images):\n",
    "            save_path = os.path.join(save_dir, f'epoch_{epoch+1}_image_{idx+1}.png')\n",
    "            save_image(image, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
